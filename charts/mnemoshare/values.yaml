# Default values for mnemoshare
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 2

image:
  repository: mnemoshare/mnemoshare
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext:
  fsGroup: 1000

securityContext:
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: false
  runAsNonRoot: true
  runAsUser: 1000

service:
  type: ClusterIP
  port: 80
  targetPort: 8080

ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/proxy-body-size: "0"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
  hosts:
    - host: mnemoshare.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: mnemoshare-tls
      hosts:
        - mnemoshare.example.com

resources:
  limits:
    cpu: 2000m
    memory: 4Gi
  requests:
    cpu: 500m
    memory: 1Gi

autoscaling:
  enabled: false
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

# Database configuration (v0.6.0+)
# Supports: mongodb (default), postgres, sqlite
database:
  # Driver: mongodb, postgres, or sqlite
  driver: "mongodb"
  # SQLite configuration (single-instance deployments only)
  sqlite:
    path: "/var/lib/mnemoshare/mnemoshare.db"

# MongoDB configuration (when database.driver = "mongodb")
mongodb:
  # If using external MongoDB
  external:
    enabled: true
    uri: ""  # mongodb://username:password@host:27017/dbname
    database: "mnemoshare"  # Database name (overrides default and URI path)
  # If deploying MongoDB as subchart (not recommended for production)
  enabled: false

# PostgreSQL configuration (when database.driver = "postgres")
postgres:
  # Connection string (DSN)
  dsn: ""  # postgres://user:password@host:5432/dbname?sslmode=disable

# S3-compatible storage configuration
s3:
  endpoint: "https://s3.amazonaws.com"
  region: "us-east-1"
  bucket: ""  # Required: your-bucket-name
  accessKey: ""  # Required: AWS_ACCESS_KEY_ID
  secretKey: ""  # Required: AWS_SECRET_ACCESS_KEY
  useSSL: true

# JWT authentication
jwt:
  secret: ""  # Required: minimum 32 characters
  expiration: "24h"

# Encryption
encryption:
  key: ""  # Required: 32-byte encryption key

# License configuration
license:
  key: ""  # Required: your license key from purchase
  # deploymentId: ""  # Optional: Override the auto-generated infrastructure-based deployment ID
  # Note: Deployment ID is now automatically generated based on namespace + cluster.
  # This ensures:
  # - All pods in the same namespace/cluster share the same deployment ID (allows scaling)
  # - Different namespace or cluster = different deployment ID (counts as separate deployment)
  # - Copying database to a new cluster generates a new ID (prevents license sharing)
  # Only set deploymentId if you need to migrate an existing deployment to a new cluster.

# SendGrid email configuration (optional)
sendgrid:
  apiKey: ""
  fromEmail: "noreply@example.com"
  fromName: "MnemoShare"

# Cloudflare Turnstile CAPTCHA (optional)
# Used to protect public forms (access requests, etc.) from bots
# Get keys from: https://dash.cloudflare.com/?to=/:account/turnstile
turnstile:
  # Public site key (embedded in frontend)
  # Default is Cloudflare's test key that always passes (for development)
  siteKey: ""  # Leave empty for test mode, or set production key
  # Private secret key (used for server-side validation)
  secretKey: ""

# Application URL
appUrl: ""  # Required: https://mnemoshare.example.com

# File upload settings
files:
  maxSize: "10737418240"  # 10GB in bytes
  defaultLinkExpiration: "168h"  # 7 days

# ============================================================================
# Disk Buffer Configuration - Memory Management for Large File Uploads
# ============================================================================
# When processing large file uploads, MnemoShare buffers chunk data during
# ICAP virus scanning and encryption. This can cause memory pressure with
# multiple concurrent large uploads. Disk buffering offloads this to disk.
#
# Behavior:
#   - ICAP enabled: Always uses disk buffering (ICAP is slow, extends memory pressure)
#   - ICAP disabled: Uses disk buffering only for files > thresholdMB
#
# IMPORTANT: Mount a dedicated volume when enabled to avoid filling node disk.
# See docs/private/DISK_BUFFER_CONFIG.md for detailed configuration guide.
diskBuffer:
  # Enable disk buffering feature
  enabled: false

  # Files larger than this threshold use disk buffering (in MB)
  # Only applies when ICAP is disabled; ICAP-enabled always uses disk buffering
  # Recommended: 1536 (1.5GB) - balances memory vs I/O overhead
  thresholdMB: 1536

  # Encrypt temp files at rest with per-file random AES-256 key
  # Provides defense-in-depth even for temporary data
  encrypt: true

  # Volume configuration for disk buffer storage
  # CRITICAL: Always mount a dedicated volume to avoid filling node ephemeral storage
  volume:
    # Volume type: "emptyDir", "ephemeral", or "existingClaim"
    type: "emptyDir"

    # emptyDir configuration (type: emptyDir)
    emptyDir:
      # Medium: "" for node disk, "Memory" for tmpfs (RAM disk)
      # Memory is fastest but uses node RAM; recommended for most deployments
      medium: "Memory"
      # Size limit - 4Gi handles ~100 concurrent chunks (20-35MB each)
      # Temp files are short-lived (deleted after each chunk processed)
      sizeLimit: "4Gi"

    # Ephemeral volume configuration (type: ephemeral)
    # Creates a temporary PVC that's deleted when pod terminates
    ephemeral:
      storageClassName: ""  # Leave empty for default, or specify fast storage (nvme, ssd)
      # 4Gi matches emptyDir default; increase for high-concurrency environments
      size: "4Gi"

    # Existing PVC configuration (type: existingClaim)
    # Use when you want persistent storage or pre-provisioned volume
    existingClaim:
      claimName: ""

# CORS settings
cors:
  allowedOrigins: ""  # Comma-separated list, e.g., "https://example.com,https://app.example.com"

# Rate limiting
rateLimit:
  requests: 100
  window: "1m"

# Liveness probe
livenessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

# Readiness probe
readinessProbe:
  httpGet:
    path: /health
    port: http
  initialDelaySeconds: 10
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 3

# Environment variables (for additional custom env vars)
extraEnv: []
# - name: CUSTOM_VAR
#   value: "custom_value"

# Existing secrets (alternative to values for sensitive data)
existingSecrets:
  mongodb: ""  # Name of existing secret with 'mongodb-uri' key
  postgres: ""  # Name of existing secret with 'postgres-dsn' key
  s3: ""       # Name of existing secret with 's3-access-key' and 's3-secret-key' keys
  jwt: ""      # Name of existing secret with 'jwt-secret' key
  encryption: ""  # Name of existing secret with 'encryption-key' key
  license: ""  # Name of existing secret with 'license-key' key

# ClamAV ICAP antivirus scanning (optional)
# Provides free, open-source virus scanning for uploaded files
clamav:
  # Enable/disable ClamAV deployment
  enabled: false

  image:
    repository: mnemoshare/clamav-icap
    tag: latest
    pullPolicy: IfNotPresent

  # ICAP endpoint configuration
  # When enabled, the ClamAV service is deployed and available at:
  #   icap://<release-name>-clamav:1344
  #
  # To use it, configure each organization's ICAP settings in the admin UI:
  #   - ICAP URL: icap://<release-name>-clamav:1344
  #   - ICAP Service: avscan
  #   - ICAP Timeout: 30 (seconds)
  #
  # You can also point organizations to external ICAP servers (commercial AV)

  # Persistence for virus definition database
  # Without persistence, definitions are re-downloaded on every pod restart (~300MB)
  persistence:
    enabled: false
    # Storage class (leave empty for default)
    storageClass: ""
    # Access mode
    accessMode: ReadWriteOnce
    # Size of the PVC (ClamAV database is ~300-400MB, 500Mi recommended)
    size: 500Mi

  # Resource limits
  # ClamAV needs memory for virus database (~1GB recommended for scanning)
  resources:
    limits:
      cpu: 1000m
      memory: 2Gi
    requests:
      cpu: 200m
      memory: 1Gi

  # Node selector for ClamAV pods
  nodeSelector: {}

  # Tolerations for ClamAV pods
  tolerations: []

# Smallstep CA - Certificate Authority for Hardware mTLS (Enterprise+ tier)
# Enables hardware-bound mTLS authentication with YubiKey, TPM 2.0, Secure Enclave
# https://smallstep.com/docs/step-ca
stepCA:
  # Enable/disable Step CA deployment
  enabled: false

  image:
    repository: smallstep/step-ca
    tag: "0.27.5"
    pullPolicy: IfNotPresent

  # CA configuration
  ca:
    # CA name (displayed in certificates)
    name: "MnemoShare CA"
    # DNS names for the CA (must include service name)
    # Format: <release-name>-step-ca.<namespace>.svc.cluster.local
    dns: "step-ca"
    # Certificate validity defaults
    minTLSCertDuration: "1h"
    maxTLSCertDuration: "2160h"    # 90 days
    defaultTLSCertDuration: "720h"  # 30 days

  # OCSP responder for certificate revocation checking
  ocsp:
    enabled: true

  # JWK provisioner for MnemoShare authentication
  provisioner:
    name: "mnemoshare"
    type: "JWK"
    # Password for provisioner key (change in production!)
    # Use existingSecret for production deployments
    password: ""

  # Use existing secret for provisioner password
  # Secret must contain 'password' key
  existingSecret: ""

  # ============================================================================
  # HSM / PKCS#11 Configuration (Enterprise+ with Hardware Security Module)
  # ============================================================================
  # Enables hardware-protected CA signing keys using PKCS#11-compatible HSMs.
  # When enabled, the CA root and intermediate keys are stored in the HSM,
  # providing FIPS 140-2/140-3 compliant key protection.
  #
  # Supported HSMs:
  #   - YubiKey 5 series (PIV mode)
  #   - Thales Luna Network HSM
  #   - AWS CloudHSM
  #   - Azure Dedicated HSM
  #   - Google Cloud HSM
  #   - SafeNet/Gemalto HSMs
  #   - SoftHSM2 (for testing only)
  #
  # IMPORTANT: HSM mode requires:
  #   1. Node with HSM access (USB passthrough or network HSM)
  #   2. Vendor-specific PKCS#11 library mounted into container
  #   3. Pre-initialized HSM with appropriate slots/tokens
  #
  # See: https://smallstep.com/docs/step-ca/cryptographic-protection/
  # ============================================================================
  hsm:
    # Enable HSM mode - switches to smallstep/step-ca-hsm image
    enabled: false

    # HSM image override (uses step-ca-hsm by default when hsm.enabled=true)
    image:
      repository: smallstep/step-ca-hsm
      tag: "0.27.5"

    # PKCS#11 Configuration
    pkcs11:
      # PKCS#11 module path inside the container
      # Examples:
      #   YubiKey:     /usr/lib/libykcs11.so
      #   SoftHSM2:    /usr/lib/softhsm/libsofthsm2.so
      #   Thales Luna: /usr/lib/libCryptoki2_64.so
      #   AWS CloudHSM: /opt/cloudhsm/lib/libcloudhsm_pkcs11.so
      modulePath: ""

      # PKCS#11 URI for the token (RFC 7512 format)
      # Examples:
      #   pkcs11:token=YubiKey%20PIV;slot-id=0
      #   pkcs11:token=hsm-token;object=ca-key;type=private
      #   pkcs11:module-path=/usr/lib/libsofthsm2.so;token=step-ca
      uri: ""

      # Token/slot PIN (use existingPinSecret for production)
      pin: ""

      # Use existing secret for PKCS#11 PIN
      # Secret must contain 'pin' key
      existingPinSecret: ""

    # Mount host PKCS#11 libraries into container
    # Required for USB HSMs (YubiKey) or vendor-specific libraries
    hostMounts:
      # Mount vendor PKCS#11 library from host
      pkcs11Lib:
        enabled: false
        # Host path to PKCS#11 .so library
        hostPath: ""
        # Mount path inside container (should match pkcs11.modulePath)
        mountPath: "/usr/lib/pkcs11/vendor.so"

      # Mount USB device for hardware tokens (YubiKey, etc.)
      usbDevice:
        enabled: false
        # USB device path (e.g., /dev/bus/usb or /dev/yubico)
        hostPath: "/dev/bus/usb"

      # Additional host mounts (for vendor-specific requirements)
      extraMounts: []
      # - name: cloudhsm-config
      #   hostPath: /opt/cloudhsm
      #   mountPath: /opt/cloudhsm
      #   readOnly: true

    # Run pcscd (PC/SC Smart Card Daemon) sidecar for USB smart cards
    # Required for YubiKey and other USB CCID devices
    pcscd:
      enabled: false
      image:
        repository: pcscd
        tag: "latest"

    # Security context overrides for HSM access
    # Some HSMs require elevated privileges or specific group membership
    securityContext:
      # Run as root (required for some USB HSM access)
      runAsRoot: false
      # Add specific capabilities (e.g., SYS_ADMIN for some HSMs)
      capabilities: []
      # - SYS_ADMIN
      # Privileged mode (last resort - not recommended)
      privileged: false

    # Node affinity for HSM-attached nodes
    # Use this to ensure the CA pod runs on a node with HSM access
    nodeAffinity:
      enabled: false
      # Label selector for HSM-capable nodes
      # Example: schedule only on nodes with label "hsm-attached=true"
      requiredNodeLabels: {}
      # hsm-attached: "true"
      # hsm-type: "yubikey"

  # Persistence for CA keys and database
  persistence:
    enabled: true
    storageClass: ""  # Leave empty for default storage class
    accessMode: ReadWriteOnce
    size: 1Gi

  # Resource limits
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 128Mi

  # Node selector for Step CA pods
  nodeSelector: {}

  # Tolerations for Step CA pods
  tolerations: []

# ============================================================================
# Alternative CA Providers (External Integration)
# ============================================================================
# MnemoShare can integrate with external Certificate Authorities for
# organizations that already have established PKI infrastructure.
#
# IMPORTANT: These are EXTERNAL integrations - MnemoShare does not deploy
# or manage these CA systems. You must have an existing deployment.
# ============================================================================

# HashiCorp Vault PKI - External CA Integration
# https://developer.hashicorp.com/vault/docs/secrets/pki
vaultPKI:
  # Enable Vault PKI integration (requires external Vault deployment)
  enabled: false

  # Vault server address
  address: ""  # e.g., https://vault.example.com:8200

  # PKI secrets engine mount path
  mountPath: "pki"

  # Role name for certificate issuance
  roleName: "mnemoshare"

  # Authentication method
  auth:
    # Method: kubernetes, token, approle
    method: "kubernetes"
    # Kubernetes auth (when method=kubernetes)
    kubernetes:
      role: "mnemoshare"
      mountPath: "auth/kubernetes"
    # Token auth (when method=token) - use existingSecret
    token:
      existingSecret: ""
      secretKey: "token"
    # AppRole auth (when method=approle)
    appRole:
      roleId: ""
      existingSecretId: ""
      secretKey: "secret-id"

  # HSM-backed keys in Vault (Vault Enterprise only)
  # ⚠️  REQUIRES VAULT ENTERPRISE LICENSE
  # When enabled, Vault uses "Managed Keys" backed by HSM/KMS
  # See: https://developer.hashicorp.com/vault/docs/enterprise/managed-keys
  managedKeys:
    enabled: false
    # Managed key name configured in Vault
    keyName: ""
    # Note: HSM/KMS configuration is done in Vault, not here

# EJBCA - External CA Integration
# https://www.ejbca.org/
ejbca:
  # Enable EJBCA integration (requires external EJBCA deployment)
  # ⚠️  MnemoShare does NOT deploy or manage EJBCA
  # You must have an existing EJBCA installation
  enabled: false

  # EJBCA REST API endpoint
  apiUrl: ""  # e.g., https://ejbca.example.com/ejbca/ejbca-rest-api

  # Certificate profile name
  certificateProfile: "mnemoshare"

  # End entity profile name
  endEntityProfile: "mnemoshare"

  # CA name in EJBCA
  caName: ""

  # Authentication
  auth:
    # Client certificate authentication (recommended)
    clientCert:
      existingSecret: ""
      certKey: "tls.crt"
      keyKey: "tls.key"

  # Note: EJBCA supports PKCS#11-backed CA keys natively
  # Configure HSM integration in EJBCA directly, not here
  # See: https://doc.primekey.com/ejbca/ejbca-operations/ejbca-ca-concept-guide/crypto-tokens

# MinIO - S3-compatible object storage (optional)
# Enable for Azure deployments or on-premise environments without S3-compatible storage
# When enabled, deploys MinIO in-cluster and auto-configures S3 endpoint
minio:
  enabled: false

  # MinIO mode: "standalone" for dev/small deployments, "distributed" for production
  mode: standalone

  # Root credentials (used if existingSecret is not set)
  # IMPORTANT: Change these defaults!
  rootUser: "mnemoshare"
  rootPassword: ""  # Required if enabled - must be at least 8 characters

  # Use existing secret for credentials
  # Secret must contain 'rootUser' and 'rootPassword' keys
  existingSecret: ""

  # Storage configuration
  persistence:
    enabled: true
    storageClass: ""  # Leave empty for default storage class
    accessMode: ReadWriteOnce
    size: 100Gi  # Adjust based on expected file storage needs

  # Resource limits
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi

  # MinIO replicas (only for distributed mode)
  replicas: 4

  # MinIO console (web UI) - useful for debugging
  consoleIngress:
    enabled: false
    # Configure if you want external access to MinIO console
    # annotations: {}
    # hosts: []
    # tls: []

# ============================================================================
# Redis - Job Queue for Workflow Workers
# ============================================================================
# Required when running the workflow worker for inbound file processing.
# Provides the Asynq job queue for distributed task processing.
redis:
  # Enable/disable Redis deployment
  enabled: false

  image:
    repository: redis
    tag: "7.2-alpine"
    pullPolicy: IfNotPresent

  # Redis password (recommended for production)
  # Use existingSecret for production deployments
  password: ""

  # Use existing secret for Redis password
  # Secret must contain 'redis-password' key
  existingSecret: ""

  # Persistence for Redis data
  persistence:
    enabled: true
    storageClass: ""  # Leave empty for default storage class
    accessMode: ReadWriteOnce
    size: 5Gi

  # Resource limits
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # Node selector for Redis pods
  nodeSelector: {}

  # Tolerations for Redis pods
  tolerations: []

# ============================================================================
# Workflow Worker - Inbound File Processing
# ============================================================================
# Processes inbound file transfers from SFTP/FTPS/rsync sources.
# Requires Redis to be enabled for the job queue.
workflowWorker:
  # Enable/disable workflow worker deployment
  enabled: false

  # Number of worker replicas (scale for more concurrent processing)
  replicas: 2

  image:
    # Uses same image as main app (workflow-worker is a separate entrypoint)
    repository: mnemoshare/mnemoshare
    tag: ""  # Defaults to chart appVersion
    pullPolicy: IfNotPresent

  # Worker concurrency (tasks per worker)
  concurrency: 10

  # Temporary directory for file processing
  # Leave empty to use system default
  tempDir: ""

  # Log level for workflow worker
  logLevel: "info"

  # ============================================================================
  # Persistence Configuration (StatefulSet mode)
  # ============================================================================
  # When enabled, workflow workers run as a StatefulSet with per-pod PVCs.
  # This solves ReadWriteOnce PVC issues with multi-replica Deployments.
  #
  # Use this when:
  #   - Running multiple workflow worker replicas
  #   - Using persistent storage for temp files (not emptyDir/ephemeral)
  #   - Processing large files that need disk buffering
  #
  # When disabled, workers run as a Deployment using diskBuffer volume config.
  persistence:
    # Enable StatefulSet mode with per-pod PVCs
    enabled: false

    # Storage class for PVCs (leave empty for default)
    storageClass: ""

    # Size of each per-pod PVC
    # Should accommodate concurrent file downloads and processing
    size: "20Gi"

  # Resource limits
  # Workers need memory for file streaming (1GB+ files)
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 2Gi

  # Node selector for worker pods
  nodeSelector: {}

  # Tolerations for worker pods
  tolerations: []

  # ============================================================================
  # KEDA Autoscaling (requires KEDA to be installed in the cluster)
  # ============================================================================
  # Scales workflow workers based on Redis queue depth.
  # Install KEDA: helm install keda kedacore/keda --namespace keda --create-namespace
  autoscaling:
    # Enable KEDA-based autoscaling
    enabled: false

    # Minimum number of workers (can scale to 0 if no pending tasks)
    minReplicas: 1

    # Maximum number of workers
    maxReplicas: 10

    # Target queue length per worker replica
    # If queue has 15 pending tasks and target is 5, KEDA will scale to 3 workers
    listLengthTarget: 5

    # How often KEDA checks queue depth (seconds)
    pollingInterval: 15

    # How long to wait before scaling down after queue is empty (seconds)
    cooldownPeriod: 60
